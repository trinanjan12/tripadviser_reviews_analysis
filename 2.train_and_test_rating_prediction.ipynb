{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee4815a",
   "metadata": {},
   "source": [
    "# Train for review prediction\n",
    "### Notebook guide:\n",
    "***This notebook has the following parts***\n",
    "1. **Loading the data set** :  Load the hotel review dataset\n",
    "2. **Preprocessing** : using mostly textacy library make lowercase,remove whitespace,replace hashtaggs,phone_numers,urls,emails,remove html_tags punctuation,replace emoji by meaning\n",
    "3. **select features** : dropping outliers i.e very long text reviews\n",
    "4. **create train test split** : spliting the data(stratify) for train test eval\n",
    "5. **dataset class and training code** : create a data loader and load model for training\n",
    "6. **main training code** : main trainer estimator\n",
    "6. **load best model and test** : checking f1 score on the test data\n",
    "\n",
    "### Note: \n",
    "Ratings are converted on a the scale of 0 to 4(from the original scale of 1-5), we can say ratings that are less than 2 are negative ratings and anything more than 2 is positive rating, 2 is neutral rating. This conversion is done for bert training.\n",
    "\n",
    "### References:\n",
    "1. https://github.com/huggingface/transformers/tree/master/examples/pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404b821",
   "metadata": {},
   "source": [
    "# 1. Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00afec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_org_data = pd.read_csv('./data/tripadvisor_hotel_reviews.csv')\n",
    "review_org_dat = review_org_data.dropna().drop_duplicates()\n",
    "review_org_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31af110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n"
     ]
    }
   ],
   "source": [
    "review_org_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885780a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20491</td>\n",
       "      <td>20491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.952223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.233030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review        Rating\n",
       "count                                               20491  20491.000000\n",
       "unique                                              20491           NaN\n",
       "top     nice hotel expensive parking got good deal sta...           NaN\n",
       "freq                                                    1           NaN\n",
       "mean                                                  NaN      3.952223\n",
       "std                                                   NaN      1.233030\n",
       "min                                                   NaN      1.000000\n",
       "25%                                                   NaN      3.000000\n",
       "50%                                                   NaN      4.000000\n",
       "75%                                                   NaN      5.000000\n",
       "max                                                   NaN      5.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_org_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96e5343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_org_data['Rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc6501",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84d60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textacy\n",
    "from textacy import preprocessing\n",
    "from emoji_translate.emoji_translate import Translator\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "emo = Translator(exact_match_only=False, randomize=True)\n",
    "\n",
    "\n",
    "def remove_stopword(x):\n",
    "    return [y for y in x.split(' ') if y not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "#     return (' ').join([y for y in x.split(' ') if y not in stopwords.words('english')])\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    '''\n",
    "     lowercase,remove whitespace,replace hashtaggs,phone_numers,urls,emails\n",
    "     remove html_tags punctuation\n",
    "     replace emoji by meaning\n",
    "    '''\n",
    "    text_new = text.lower()\n",
    "    text_new = re.sub(' +', ' ', text_new)\n",
    "    text_new = textacy.preprocessing.replace.hashtags(text_new, repl='_HASH_')\n",
    "    text_new = textacy.preprocessing.replace.phone_numbers(text_new,\n",
    "                                                           repl='_PHONENUM_')\n",
    "    text_new = textacy.preprocessing.remove.html_tags(text_new)\n",
    "    text_new = textacy.preprocessing.replace.urls(text_new, repl='_URL_')\n",
    "    text_new = textacy.preprocessing.replace.emails(text_new, repl='_EMAIL_')\n",
    "    text_new = textacy.preprocessing.remove.punctuation(text_new,\n",
    "                                                        only=[\",\", \";\", \":\"])\n",
    "    text_new = emo.demojify(text_new)\n",
    "    return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c714b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: using parallel processing here to make it faster\n",
    "review_org_data['clean_text'] = review_org_data['Review'].apply(\n",
    "    lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5ab79",
   "metadata": {},
   "source": [
    "# 3. Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8c3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting rating from 0 to 4\n",
    "review_org_data['rating_from_0'] = review_org_data['Rating'].apply(\n",
    "    lambda x: x - 1)\n",
    "# checking text_length of reviews\n",
    "review_org_data['text_length'] = review_org_data['clean_text'].apply(\n",
    "    lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ad1353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of reviews having more than 512 words are 262\n"
     ]
    }
   ],
   "source": [
    "print('num of reviews having more than 512 words are ', end='')\n",
    "print(\n",
    "    len(review_org_data) -\n",
    "    len(review_org_data[review_org_data['text_length'] < 512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95f0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove them\n",
    "review_org_data = review_org_data[review_org_data['text_length'] < 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35ad737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_org_data[review_org_data['rating_from_0'] == 4].sort_values('text_length',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e340c",
   "metadata": {},
   "source": [
    "# 4. Create train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a2338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train and test split ....\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print('creating train and test split ....')\n",
    "\n",
    "X = review_org_data['clean_text']\n",
    "y = review_org_data['rating_from_0']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,stratify=y, test_size=0.2, random_state = 2022)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_test, y_test, stratify=y_test, test_size=0.5,random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502701bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16183, 2023, 2023)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_val),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a6dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 140, 3: 595, 2: 215, 4: 898, 1: 175}),\n",
       " Counter({4: 897, 3: 595, 0: 140, 1: 176, 2: 215}))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(list(y_val)),Counter(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08787ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8698ad",
   "metadata": {},
   "source": [
    "# 5. Dataset class, Model Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b764d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc8db0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = t.BertTokenizer.from_pretrained(model_ckpt)\n",
    "model = t.BertForSequenceClassification.from_pretrained(model_ckpt, num_labels=5).to(\"cuda\")\n",
    "\n",
    "for name, param in model.bert.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f69588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0bdd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, reviews, ratings, tokenizer):\n",
    "\n",
    "        self.reviews = reviews\n",
    "        self.ratings = ratings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = tokenizer.model_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = str(self.reviews[index])\n",
    "        ratings = self.ratings[index]\n",
    "\n",
    "        encoded_review = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_review['input_ids'][0],\n",
    "            'attention_mask': encoded_review['attention_mask'][0],\n",
    "            'labels': torch.tensor(ratings, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e9f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Create_Dataset(\n",
    "    reviews=list(X_train),\n",
    "    ratings=list(y_train),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "validation_dataset = Create_Dataset(\n",
    "    reviews=list(X_val),\n",
    "    ratings=list(y_val),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "test_dataset = Create_Dataset(\n",
    "    reviews=list(X_test),\n",
    "    ratings=list(y_test),\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0682d29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16183, 2023, 2023)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),len(validation_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c2fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512]) torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "# todo add number to token code \n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size  = 16,\n",
    "    num_workers = 4\n",
    ")\n",
    "testing_data = next(iter(test_dataloader))\n",
    "print( testing_data[\"input_ids\"].size(), testing_data[\"input_ids\"].size() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc04ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# todo check this\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264115cd",
   "metadata": {},
   "source": [
    "# 6. Main training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6973ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = t.TrainingArguments(output_dir=\"./sentiment_analysis\",\n",
    "                                    num_train_epochs=10,\n",
    "                                    per_device_train_batch_size=8,\n",
    "                                    per_device_eval_batch_size=8,\n",
    "                                    warmup_steps=500,\n",
    "                                    weight_decay=0.01,\n",
    "                                    evaluation_strategy=\"epoch\",\n",
    "                                    save_steps=5000)\n",
    "\n",
    "trainer = t.Trainer(model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=validation_dataset,\n",
    "                    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c02d940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='20230' max='20230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20230/20230 1:43:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>0.878821</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>21.877600</td>\n",
       "      <td>92.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.765626</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>21.821600</td>\n",
       "      <td>92.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.822622</td>\n",
       "      <td>0.675729</td>\n",
       "      <td>0.675729</td>\n",
       "      <td>0.675729</td>\n",
       "      <td>0.675729</td>\n",
       "      <td>21.868600</td>\n",
       "      <td>92.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>1.104687</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>21.847200</td>\n",
       "      <td>92.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>1.566481</td>\n",
       "      <td>0.665348</td>\n",
       "      <td>0.665348</td>\n",
       "      <td>0.665348</td>\n",
       "      <td>0.665348</td>\n",
       "      <td>21.841400</td>\n",
       "      <td>92.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>1.877496</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>21.845400</td>\n",
       "      <td>92.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>2.097359</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>21.862400</td>\n",
       "      <td>92.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>2.441432</td>\n",
       "      <td>0.659417</td>\n",
       "      <td>0.659417</td>\n",
       "      <td>0.659417</td>\n",
       "      <td>0.659417</td>\n",
       "      <td>21.839200</td>\n",
       "      <td>92.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>2.572223</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>21.853800</td>\n",
       "      <td>92.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>2.744066</td>\n",
       "      <td>0.660405</td>\n",
       "      <td>0.660405</td>\n",
       "      <td>0.660405</td>\n",
       "      <td>0.660405</td>\n",
       "      <td>21.840600</td>\n",
       "      <td>92.626000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20230, training_loss=0.3632042271278898, metrics={'train_runtime': 6191.2952, 'train_samples_per_second': 3.267, 'total_flos': 54430104992409600, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41021b",
   "metadata": {},
   "source": [
    "# 7. Load trained model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c64a7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"sentiment_analysis/checkpoint-20000/\"\n",
    "tokenizer = t.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = t.BertForSequenceClassification.from_pretrained(model_ckpt, num_labels=5).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30dbd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trainer = t.Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc7b0650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='253' max='253' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [253/253 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_pred = test_trainer.predict(test_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bad6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66       140\n",
      "           1       0.50      0.57      0.53       176\n",
      "           2       0.47      0.45      0.46       215\n",
      "           3       0.56      0.58      0.57       595\n",
      "           4       0.78      0.77      0.78       897\n",
      "\n",
      "    accuracy                           0.65      2023\n",
      "   macro avg       0.61      0.60      0.60      2023\n",
      "weighted avg       0.65      0.65      0.65      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(list(final_pred.label_ids),list(final_pred.predictions.argmax(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f084b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
